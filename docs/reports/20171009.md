# Rapport - Semaine du 09/10/2017

* Fin de la collecte de l'intégralité des >3M de pages people (toutes langues).
* Dump d'un fichier contenant la liste des pages désormais caduques (404 => 21 720 pages) et erronées (400 => 279 pages) pour information et ajustement des données actuelles.
* Développement d'un script python parallélisé pour extraire les liens des pages location depuis les pages people récupérée. Ajustement des heuristiques pour filtrer les liens de location évidemment non pertinents.
* Estimation du temps de calcul nécessaire pour extraire les liens des 3M de pages: minimum 6h en utilisant 6 CPUs (analyse de 60Go de HTML compressé).
* Début de l'extraction des liens sur les 3M de pages people.
* Creation de la queue de processing Mongo pour les pages locations.
* Crawl des 330k pages locations.
* Creation d'un script d'export des liens people/location pour intégration dans les bases Stata de Morgane si besoin.
* Fin de l'extraction des liens (14h de traitement avec 6 CPUs). Exportation des liens dans un fichier CSV.

Concernant la suite:

* Il semble que la liste des fichiers que j'ai traité soit incomplète. Besoin de crawler les pages manquantes et refaire tourner l'extraction des liens. Besoin d'adapter les scripts pour les rendre capable de gérer une queue partielle). En attente du fichier de Morgane.
* Utiliser les liens extraits pour mettre à jour le datascape et pouvoir faire évoluer les pages people/locations (les liens people => location sont pour l'instant des ensembles uniques non-ordonnés).
* Analyse des pages de locations pour:
  - Récupérer les liens vers les autres langues et pouvoir associer facilement les locations et leur traductions.
  - Parser l'infobox et les catégories etc. pour récupérer un maximum d'information afin de commencer à dresser une typologie partielle des locations.
  - Utiliser du machine learning pour essayer de propager la typologie partielle des locations aux pages sans autre information que le contenu textuel.
  - En cas d'échec, utiliser des techniques de topic-modeling.
* Affinage de l'extraction des liens prenant en compte le contexte d'appartition pour passer d'ensembles uniques à des listes pseudo-chronologiques et pondérées. Cela nécessite un travail de compréhension algorithmique de la langue (port des mes algorithmes en python ou entraînement d'un tokenizer Punkt dans les 7 langues considérées).
* Documenter mes scripts.
